{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import psutil\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a 1D Gaussian Mixture Model (GMM)\n",
    "def log_prob(x):\n",
    "    \"\"\"Compute log probability of a Gaussian mixture model.\"\"\"\n",
    "    x = x.to(device).requires_grad_(True)\n",
    "    p1 = torch.exp(-0.5 * ((x - 2) / 0.8) ** 2) / (0.8 * (2 * torch.pi) ** 0.5)\n",
    "    p2 = torch.exp(-0.5 * ((x + 2) / 0.8) ** 2) / (0.8 * (2 * torch.pi) ** 0.5)\n",
    "    return torch.log(0.5 * p1 + 0.5 * p2 + 1e-9)  # Small constant for numerical stability\n",
    "\n",
    "# Measure memory usage on CUDA\n",
    "def get_memory_usage():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()  # Ensure all GPU operations are completed\n",
    "        return torch.cuda.max_memory_allocated() / (1024**2)  # Peak memory in MB\n",
    "    else:\n",
    "        return psutil.Process().memory_info().rss / (1024**2)  # CPU memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the true score function using autograd\n",
    "def true_score(x, step, step_size):\n",
    "    x = x.to(device)\n",
    "    log_p = log_prob(x)\n",
    "    grad = step_size * torch.autograd.grad(log_p.sum(), x, create_graph=True)[0]\n",
    "    return grad.detach(), step_size\n",
    "\n",
    "# Estimate the score function using finite differences\n",
    "def KW(x, step, step_size, delta=5e-2):\n",
    "    x = x.to(device)\n",
    "    step_size = (1 + step_size) ** 0.6\n",
    "    delta = step_size * torch.tensor(delta / (step + 1) ** 0.5, device=device)  # Adaptive step size\n",
    "    return (log_prob(x + delta) - log_prob(x - delta)) / (2 * delta), step_size\n",
    "\n",
    "# SPSA Gradient Estimation\n",
    "def spsa_gradient(x, step, step_size, delta=5e-2):\n",
    "    x = x.to(device)\n",
    "    step_size = (1 + step_size) ** 0.6\n",
    "    perturbation = torch.empty_like(x).uniform_(-1, 1).sign()\n",
    "    delta = step_size * torch.tensor(delta / (step + 1) ** 0.5, device=device)  # Adaptive step size\n",
    "    x_plus = x + delta * perturbation\n",
    "    x_minus = x - delta * perturbation\n",
    "    gradient_estimate = (log_prob(x_plus) - log_prob(x_minus)) / (2 * delta * perturbation)\n",
    "    return gradient_estimate, step_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langevin Dynamics sampler with better exploration\n",
    "def langevin_dynamics(x0_list, score_function, steps=100, eta=0.5, noise_scale=0.1):\n",
    "    \"\"\"Perform Langevin Dynamics using a specified score function, with multiple initial points.\"\"\"\n",
    "    x = x0_list.to(device)\n",
    "    samples = []\n",
    "\n",
    "    for i in range(steps):\n",
    "        score, step_size = score_function(x, i, eta)  # Compute score function\n",
    "        noise = torch.randn_like(x, device=device)  # Reduce noise over time\n",
    "        x = x + score + torch.sqrt(torch.tensor(2 * step_size, device=device)) * noise\n",
    "        samples.append(x.clone().detach())\n",
    "\n",
    "    return torch.cat(samples)\n",
    "\n",
    "# Hamiltonian Monte Carlo sampler without Metropolis step\n",
    "def hmc_sampler(x0_list, score_function, steps=100, leapfrog_steps=3, step_size=0.1):\n",
    "    \"\"\"Perform Hamiltonian Monte Carlo sampling with multiple initial points using a specified score function.\"\"\"\n",
    "    x = x0_list.to(device)\n",
    "    samples = []\n",
    "\n",
    "    for _ in range(steps):\n",
    "        x = x.clone().detach().requires_grad_(True)\n",
    "        p = torch.randn_like(x, device=device)\n",
    "\n",
    "        for _ in range(leapfrog_steps):\n",
    "            score, _ = score_function(x, _, step_size)\n",
    "            p = p - 0.5 * step_size * score\n",
    "            x = x + step_size * p\n",
    "            score, _ = score_function(x, _, step_size)\n",
    "            p = p - 0.5 * step_size * score\n",
    "        \n",
    "        samples.append(x.clone().detach())\n",
    "\n",
    "    return torch.cat(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment configurations\n",
    "num_samples_list = [1, 10, 100, 1000, 10000]\n",
    "steps_list = [1, 10, 100, 1000, 10000]\n",
    "results = []\n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "results_dir = \"results_univariate\"\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiments\n",
    "for num_samples in num_samples_list:\n",
    "    for steps in steps_list:\n",
    "        x0_list = torch.randn(num_samples, device=device)\n",
    "\n",
    "        # Benchmarking True Gradients (Langevin)\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()  # Reset memory tracking\n",
    "        start_time = time.perf_counter()\n",
    "        mem_before = get_memory_usage()\n",
    "        samples_true = langevin_dynamics(x0_list, true_score, steps)\n",
    "        torch.cuda.synchronize()\n",
    "        mem_after = get_memory_usage()\n",
    "        time_true = time.perf_counter() - start_time\n",
    "        mem_true = mem_after - mem_before\n",
    "\n",
    "        # Benchmarking Finite Differences (Langevin)\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()  # Reset memory tracking\n",
    "        start_time = time.perf_counter()\n",
    "        mem_before = get_memory_usage()\n",
    "        samples_estimated = langevin_dynamics(x0_list, KW, steps)\n",
    "        torch.cuda.synchronize()\n",
    "        mem_after = get_memory_usage()\n",
    "        time_estimated = time.perf_counter() - start_time\n",
    "        mem_estimated = mem_after - mem_before\n",
    "\n",
    "        # Benchmarking SPSA (Langevin)\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()  # Reset memory tracking\n",
    "        start_time = time.perf_counter()\n",
    "        mem_before = get_memory_usage()\n",
    "        samples_spsa = langevin_dynamics(x0_list, spsa_gradient, steps)\n",
    "        torch.cuda.synchronize()\n",
    "        mem_after = get_memory_usage()\n",
    "        time_spsa = time.perf_counter() - start_time\n",
    "        mem_spsa = mem_after - mem_before\n",
    "\n",
    "        # Benchmarking True Gradients (HMC)\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()  # Reset memory tracking\n",
    "        start_time = time.perf_counter()\n",
    "        mem_before = get_memory_usage()\n",
    "        samples_hmc_true = hmc_sampler(x0_list, true_score, steps)\n",
    "        torch.cuda.synchronize()\n",
    "        mem_after = get_memory_usage()\n",
    "        time_hmc_true = time.perf_counter() - start_time\n",
    "        mem_hmc_true = mem_after - mem_before\n",
    "\n",
    "        # Benchmarking Finite Differences (HMC)\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()  # Reset memory tracking\n",
    "        start_time = time.perf_counter()\n",
    "        mem_before = get_memory_usage()\n",
    "        samples_hmc_estimated = hmc_sampler(x0_list, KW, steps)\n",
    "        torch.cuda.synchronize()\n",
    "        mem_after = get_memory_usage()\n",
    "        time_hmc_estimated = time.perf_counter() - start_time\n",
    "        mem_hmc_estimated = mem_after - mem_before\n",
    "\n",
    "        # Benchmarking SPSA (HMC)\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()  # Reset memory tracking\n",
    "        start_time = time.perf_counter()\n",
    "        mem_before = get_memory_usage()\n",
    "        samples_hmc_spsa = hmc_sampler(x0_list, spsa_gradient, steps)\n",
    "        torch.cuda.synchronize()\n",
    "        mem_after = get_memory_usage()\n",
    "        time_hmc_spsa = time.perf_counter() - start_time\n",
    "        mem_hmc_spsa = mem_after - mem_before\n",
    "\n",
    "        # Collect all steps for convergence analysis\n",
    "        all_steps_true = langevin_dynamics(x0_list, true_score, steps).cpu().numpy()\n",
    "        all_steps_estimated = langevin_dynamics(x0_list, KW, steps).cpu().numpy()\n",
    "        all_steps_spsa = langevin_dynamics(x0_list, spsa_gradient, steps).cpu().numpy()\n",
    "        all_steps_hmc_true = hmc_sampler(x0_list, true_score, steps).cpu().numpy()\n",
    "        all_steps_hmc_estimated = hmc_sampler(x0_list, KW, steps).cpu().numpy()\n",
    "        all_steps_hmc_spsa = hmc_sampler(x0_list, spsa_gradient, steps).cpu().numpy()\n",
    "\n",
    "        # Collect results\n",
    "        results.append({\n",
    "            \"num_samples\": num_samples,\n",
    "            \"steps\": steps,\n",
    "            \"time_true\": time_true,\n",
    "            \"mem_true\": mem_true,\n",
    "            \"time_estimated\": time_estimated,\n",
    "            \"mem_estimated\": mem_estimated,\n",
    "            \"time_spsa\": time_spsa,\n",
    "            \"mem_spsa\": mem_spsa,\n",
    "            \"time_hmc_true\": time_hmc_true,\n",
    "            \"mem_hmc_true\": mem_hmc_true,\n",
    "            \"time_hmc_estimated\": time_hmc_estimated,\n",
    "            \"mem_hmc_estimated\": mem_hmc_estimated,\n",
    "            \"time_hmc_spsa\": time_hmc_spsa,\n",
    "            \"mem_hmc_spsa\": mem_hmc_spsa,\n",
    "            \"all_steps_true\": all_steps_true.tolist(),\n",
    "            \"all_steps_estimated\": all_steps_estimated.tolist(),\n",
    "            \"all_steps_spsa\": all_steps_spsa.tolist(),\n",
    "            \"all_steps_hmc_true\": all_steps_hmc_true.tolist(),\n",
    "            \"all_steps_hmc_estimated\": all_steps_hmc_estimated.tolist(),\n",
    "            \"all_steps_hmc_spsa\": all_steps_hmc_spsa.tolist()\n",
    "        })\n",
    "        print(f\"Completed: num_samples = {num_samples}, steps = {steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to file\n",
    "results_filename = os.path.join(results_dir, 'results_univariate.json')\n",
    "with open(results_filename, 'w') as f:\n",
    "    json.dump(results, f)\n",
    "print(f\"Results saved to {results_filename}\")\n",
    "\n",
    "colors = {\n",
    "    'LD - True Gradients': 'blue',\n",
    "    'LD - KW': 'green',\n",
    "    'LD - SPSA': 'red',\n",
    "    'HMC - True Gradients': 'purple',\n",
    "    'HMC - KW': 'orange',\n",
    "    'HMC - SPSA': 'brown'\n",
    "}\n",
    "\n",
    "x_vals = torch.linspace(-5, 5, 1000).to(device)\n",
    "true_density = torch.exp(log_prob(x_vals)).detach().cpu().numpy()\n",
    "# Plot convergence\n",
    "def plot_convergence(results, num_samples, steps, filename):\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    for result in results:\n",
    "        if result[\"num_samples\"] == num_samples and result[\"steps\"] == steps:\n",
    "            samples_true = torch.tensor((result[\"all_steps_true\"])).view(num_samples, steps)\n",
    "            samples_estimated = torch.tensor((result[\"all_steps_estimated\"])).view(num_samples, steps)\n",
    "            samples_spsa = torch.tensor(result[\"all_steps_spsa\"]).view(num_samples, steps)\n",
    "            samples_hmc_true = torch.tensor(result[\"all_steps_hmc_true\"]).view(num_samples, steps)\n",
    "            samples_hmc_estimated = torch.tensor(result[\"all_steps_hmc_estimated\"]).view(num_samples, steps)\n",
    "            samples_hmc_spsa = torch.tensor(result[\"all_steps_hmc_spsa\"]).view(num_samples, steps)\n",
    "            \n",
    "            for i in range(num_samples):\n",
    "                fig.add_trace(go.Scatter(y=samples_true[i], mode='lines', name=f'LD - True Gradients', opacity=0.5, legendgroup='LD - True Gradients', line=dict(color=colors['LD - True Gradients']), showlegend=(i == 0)))\n",
    "                fig.add_trace(go.Scatter(y=samples_estimated[i], mode='lines', name=f'LD - KW (num_sample={result[\"num_samples\"]})', opacity=0.5, legendgroup='LD - KW', line=dict(color=colors['LD - KW']), showlegend=(i == 0)))\n",
    "                fig.add_trace(go.Scatter(y=samples_spsa[i], mode='lines', name=f'LD - SPSA (num_sample={result[\"num_samples\"]})', opacity=0.5, legendgroup='LD - SPSA', line=dict(color=colors['LD - SPSA']), showlegend=(i == 0)))\n",
    "                fig.add_trace(go.Scatter(y=samples_hmc_true[i], mode='lines', name=f'HMC - True Gradients (num_sample={result[\"num_samples\"]})', opacity=0.5, legendgroup='HMC - True Gradients', line=dict(color=colors['HMC - True Gradients']), showlegend=(i == 0)))\n",
    "                fig.add_trace(go.Scatter(y=samples_hmc_estimated[i], mode='lines', name=f'HMC - KW (num_sample={result[\"num_samples\"]})', opacity=0.5, legendgroup='HMC - KW', line=dict(color=colors['HMC - KW']), showlegend=(i == 0)))\n",
    "                fig.add_trace(go.Scatter(y=samples_hmc_spsa[i], mode='lines', name=f'HMC - SPSA (num_sample={result[\"num_samples\"]})', opacity=0.5, legendgroup='HMC - SPSA', line=dict(color=colors['HMC - SPSA']), showlegend=(i == 0)))\n",
    "                \n",
    "    fig.update_layout(title=f'Convergence Plot for steps={steps}',\n",
    "                      xaxis_title='Steps',\n",
    "                      yaxis_title='Sample Value',\n",
    "                      legend_title_text='Methods')\n",
    "    fig.write_html(filename)\n",
    "    print(f\"Plot saved to {filename}\")\n",
    "\n",
    "# Plot histogram comparison\n",
    "def plot_histogram_comparison(results, num_samples, steps, filename):\n",
    "    for result in results:\n",
    "        if result[\"num_samples\"] == num_samples and result[\"steps\"] == steps:\n",
    "            assert len(result[\"all_steps_true\"]) == num_samples*steps\n",
    "            samples_true = torch.tensor((result[\"all_steps_true\"])).view(num_samples, steps)[:, -1]\n",
    "            samples_estimated = torch.tensor((result[\"all_steps_estimated\"])).view(num_samples, steps)[:, -1]\n",
    "            samples_spsa = torch.tensor(result[\"all_steps_spsa\"]).view(num_samples, steps)[:, -1]\n",
    "            samples_hmc_true = torch.tensor(result[\"all_steps_hmc_true\"]).view(num_samples, steps)[:, -1]\n",
    "            samples_hmc_estimated = torch.tensor(result[\"all_steps_hmc_estimated\"]).view(num_samples, steps)[:, -1]\n",
    "            samples_hmc_spsa = torch.tensor(result[\"all_steps_hmc_spsa\"]).view(num_samples, steps)[:, -1]\n",
    "\n",
    "            fig = go.Figure()\n",
    "            fig.add_trace(go.Histogram(x=samples_true, nbinsx=100, histnorm='probability density', name='LD - True Gradients', opacity=0.5))\n",
    "            fig.add_trace(go.Histogram(x=samples_estimated, nbinsx=100, histnorm='probability density', name='LD - KW', opacity=0.5))\n",
    "            fig.add_trace(go.Histogram(x=samples_spsa, nbinsx=100, histnorm='probability density', name='LD - SPSA', opacity=0.5))\n",
    "            fig.add_trace(go.Histogram(x=samples_hmc_true, nbinsx=100, histnorm='probability density', name='HMC - True Gradients', opacity=0.5))\n",
    "            fig.add_trace(go.Histogram(x=samples_hmc_estimated, nbinsx=100, histnorm='probability density', name='HMC - KW', opacity=0.5))\n",
    "            fig.add_trace(go.Histogram(x=samples_hmc_spsa, nbinsx=100, histnorm='probability density', name='HMC - SPSA', opacity=0.5))\n",
    "            fig.add_trace(go.Scatter(x=x_vals.detach().cpu().numpy(), y=true_density, mode='lines', name='True Distribution', line=dict(color='black', width=2)))\n",
    "\n",
    "            fig.update_layout(\n",
    "                title=f'Histogram Comparison for num_samples={num_samples}, steps={steps}',\n",
    "                xaxis_title='Sample Value',\n",
    "                yaxis_title='Density',\n",
    "                barmode='overlay'\n",
    "            )\n",
    "\n",
    "            fig.write_html(filename)\n",
    "            print(f\"Plot saved to {filename}\")\n",
    "\n",
    "num_samples = 10000\n",
    "steps = 1000\n",
    "# Example plot for specific num_samples and steps\n",
    "plot_histogram_comparison(results, num_samples, steps, os.path.join(results_dir, f'histogram_comparison_{num_samples}_{steps}.html'))\n",
    "\n",
    "\n",
    "num_samples = 1\n",
    "steps = 1000\n",
    "# Example plot for specific num_samples and steps\n",
    "plot_convergence(results, num_samples, steps, os.path.join(results_dir, f'convergence_plot_{num_samples}_{steps}.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "# Load results from file\n",
    "results_dir = \"results_univariate\"\n",
    "results_filename = os.path.join(results_dir, 'results_univariate.json')\n",
    "with open(results_filename, 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Compute true density\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def log_prob(x):\n",
    "    \"\"\"Compute log probability of a Gaussian mixture model.\"\"\"\n",
    "    x = x.to(device).requires_grad_(True)\n",
    "    p1 = torch.exp(-0.5 * ((x - 2) / 0.8) ** 2) / (0.8 * (2 * torch.pi) ** 0.5)\n",
    "    p2 = torch.exp(-0.5 * ((x + 2) / 0.8) ** 2) / (0.8 * (2 * torch.pi) ** 0.5)\n",
    "    return torch.log(0.5 * p1 + 0.5 * p2 + 1e-9)  # Small constant for numerical stability\n",
    "\n",
    "x_vals = torch.linspace(-5, 5, 1000).to(device)\n",
    "true_density = torch.exp(log_prob(x_vals)).detach().cpu().numpy()\n",
    "\n",
    "# Calculate Wasserstein distance\n",
    "def calculate_wasserstein_distance(results):\n",
    "    wassersteins = []\n",
    "    for result in results:\n",
    "        samples_true = result[\"all_steps_true\"]\n",
    "        samples_estimated = result[\"all_steps_estimated\"]\n",
    "        samples_spsa = result[\"all_steps_spsa\"]\n",
    "        samples_hmc_true = result[\"all_steps_hmc_true\"]\n",
    "        samples_hmc_estimated = result[\"all_steps_hmc_estimated\"]\n",
    "        samples_hmc_spsa = result[\"all_steps_hmc_spsa\"]\n",
    "\n",
    "        wasserstein_true = wasserstein_distance(samples_true, true_density)\n",
    "        wasserstein_estimated = wasserstein_distance(samples_estimated, true_density)\n",
    "        wasserstein_spsa = wasserstein_distance(samples_spsa, true_density)\n",
    "        wasserstein_hmc_true = wasserstein_distance(samples_hmc_true, true_density)\n",
    "        wasserstein_hmc_estimated = wasserstein_distance(samples_hmc_estimated, true_density)\n",
    "        wasserstein_hmc_spsa = wasserstein_distance(samples_hmc_spsa, true_density)\n",
    "\n",
    "        wassersteins.append({\n",
    "            \"num_samples\": result[\"num_samples\"],\n",
    "            \"steps\": result[\"steps\"],\n",
    "            \"wasserstein_true\": wasserstein_true,\n",
    "            \"wasserstein_estimated\": wasserstein_estimated,\n",
    "            \"wasserstein_spsa\": wasserstein_spsa,\n",
    "            \"wasserstein_hmc_true\": wasserstein_hmc_true,\n",
    "            \"wasserstein_hmc_estimated\": wasserstein_hmc_estimated,\n",
    "            \"wasserstein_hmc_spsa\": wasserstein_hmc_spsa\n",
    "        })\n",
    "    return wassersteins\n",
    "\n",
    "wassersteins = calculate_wasserstein_distance(results)\n",
    "\n",
    "# Plot Wasserstein distance as a function of steps\n",
    "def plot_wasserstein_vs_steps(wassersteins, num_samples):\n",
    "    steps = sorted(list(set(r[\"steps\"] for r in wassersteins)))\n",
    "    wasserstein_true = [r[\"wasserstein_true\"] for r in wassersteins if r[\"num_samples\"] == num_samples]\n",
    "    wasserstein_estimated = [r[\"wasserstein_estimated\"] for r in wassersteins if r[\"num_samples\"] == num_samples]\n",
    "    wasserstein_spsa = [r[\"wasserstein_spsa\"] for r in wassersteins if r[\"num_samples\"] == num_samples]\n",
    "    wasserstein_hmc_true = [r[\"wasserstein_hmc_true\"] for r in wassersteins if r[\"num_samples\"] == num_samples]\n",
    "    wasserstein_hmc_estimated = [r[\"wasserstein_hmc_estimated\"] for r in wassersteins if r[\"num_samples\"] == num_samples]\n",
    "    wasserstein_hmc_spsa = [r[\"wasserstein_hmc_spsa\"] for r in wassersteins if r[\"num_samples\"] == num_samples]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(steps, wasserstein_true, label=\"LD - True Gradients\")\n",
    "    plt.plot(steps, wasserstein_estimated, label=\"LD - KW\")\n",
    "    plt.plot(steps, wasserstein_spsa, label=\"LD - SPSA\")\n",
    "    plt.plot(steps, wasserstein_hmc_true, label=\"HMC - True Gradients\")\n",
    "    plt.plot(steps, wasserstein_hmc_estimated, label=\"HMC - KW\")\n",
    "    plt.plot(steps, wasserstein_hmc_spsa, label=\"HMC - SPSA\")\n",
    "    plt.xlabel(\"Number of Steps\")\n",
    "    plt.ylabel(\"Wasserstein Distance\")\n",
    "    plt.title(f\"Wasserstein Distance vs. Steps (num_samples={num_samples})\")\n",
    "    plt.legend()\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.savefig(os.path.join(results_dir, f'wasserstein_vs_steps_{num_samples}.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Plot Wasserstein distance as a function of samples\n",
    "def plot_wasserstein_vs_samples(wassersteins, steps):\n",
    "    num_samples = sorted(list(set(r[\"num_samples\"] for r in wassersteins)))\n",
    "    wasserstein_true = [r[\"wasserstein_true\"] for r in wassersteins if r[\"steps\"] == steps]\n",
    "    wasserstein_estimated = [r[\"wasserstein_estimated\"] for r in wassersteins if r[\"steps\"] == steps]\n",
    "    wasserstein_spsa = [r[\"wasserstein_spsa\"] for r in wassersteins if r[\"steps\"] == steps]\n",
    "    wasserstein_hmc_true = [r[\"wasserstein_hmc_true\"] for r in wassersteins if r[\"steps\"] == steps]\n",
    "    wasserstein_hmc_estimated = [r[\"wasserstein_hmc_estimated\"] for r in wassersteins if r[\"steps\"] == steps]\n",
    "    wasserstein_hmc_spsa = [r[\"wasserstein_hmc_spsa\"] for r in wassersteins if r[\"steps\"] == steps]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(num_samples, wasserstein_true, label=\"LD - True Gradients\")\n",
    "    plt.plot(num_samples, wasserstein_estimated, label=\"LD -KW\")\n",
    "    plt.plot(num_samples, wasserstein_spsa, label=\"LS - SPSA\")\n",
    "    plt.plot(num_samples, wasserstein_hmc_true, label=\"HMC - True Gradients\")\n",
    "    plt.plot(num_samples, wasserstein_hmc_estimated, label=\"HMC - KW\")\n",
    "    plt.plot(num_samples, wasserstein_hmc_spsa, label=\"HMC - SPSA\")\n",
    "    plt.xlabel(\"Number of Samples\")\n",
    "    plt.ylabel(\"Wasserstein Distance\")\n",
    "    plt.title(f\"Wasserstein Distance vs. Samples (steps={steps})\")\n",
    "    plt.legend()\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.savefig(os.path.join(results_dir, f'wasserstein_vs_samples_{steps}.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Generate plots for all configurations\n",
    "num_samples_list = [1, 10, 100, 1000, 10000]\n",
    "steps_list = [1, 10, 100, 1000, 10000]\n",
    "\n",
    "for num_samples in num_samples_list:\n",
    "    plot_wasserstein_vs_steps(wassersteins, num_samples)\n",
    "\n",
    "for steps in steps_list:\n",
    "    plot_wasserstein_vs_samples(wassersteins, steps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
